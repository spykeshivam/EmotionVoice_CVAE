{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bf4f801-8bb0-481c-a749-24642eb4aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "THIS NOTEBOOK CONTAINS ALL THE CODE FOR DATASET CREATION. \n",
    "CHECK main.ipynb FOR MODEL TRAINING CODE\n",
    "'''\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import zipfile\n",
    "\n",
    "from config import (\n",
    "    DEVICE, \n",
    "    LATENT_DIM, \n",
    "    EMOTION_DIM, \n",
    "    LEARNING_RATE, \n",
    "    EPOCHS, \n",
    "    BETA,\n",
    "    MODEL_DIR, \n",
    "    PLOT_OUTPUT_DIR,\n",
    "    N_MELS,\n",
    "    MAX_AUDIO_LENGTH,\n",
    "    HOP_LENGTH,\n",
    "    N_FFT,\n",
    "    SAMPLE_RATE,\n",
    "    EMOTION_CATEGORIES,\n",
    "    GL_ITERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77636fcb-d35f-4284-a97e-2a4104987791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4deef9-c1c0-43a0-9118-00364e1d0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9035f574-7a8b-4dec-b8a2-e0d2c3e62a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.11/site-packages (0.3.12)\n",
      "Requirement already satisfied: pygame in /opt/conda/lib/python3.11/site-packages (2.6.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from kagglehub) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08eed2f4-1224-4575-b5a8-1494f9ca43e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import kagglehub\\n\\n# Download latest version\\npath = kagglehub.dataset_download(\"uldisvalainis/audio-emotions\")\\n\\nprint(\"Path to dataset files:\", path)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"uldisvalainis/audio-emotions\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da86e315-5876-43ee-9bf5-0b187d92d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pygame\n",
    "import os\n",
    "from IPython.display import display, Audio\n",
    "import time\n",
    "\n",
    "def play_audio_jupyter(file_path, use_pygame=False):\n",
    "    \"\"\"\n",
    "    Play an audio file in a Jupyter notebook\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the audio file\n",
    "        use_pygame (bool): Whether to use pygame for playback instead of IPython's Audio\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "    \n",
    "    if use_pygame:\n",
    "        # Initialize pygame mixer\n",
    "        pygame.mixer.init()\n",
    "        try:\n",
    "            # Load and play the sound\n",
    "            sound = pygame.mixer.Sound(file_path)\n",
    "            print(f\"Playing: {file_path}\")\n",
    "            print(f\"Duration: {sound.get_length():.2f} seconds\")\n",
    "            \n",
    "            # Play the sound\n",
    "            sound.play()\n",
    "            \n",
    "            # Keep the program running while the sound is playing\n",
    "            pygame.time.wait(int(sound.get_length() * 1000))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error playing audio with pygame: {e}\")\n",
    "        finally:\n",
    "            # Clean up resources\n",
    "            pygame.mixer.quit()\n",
    "    else:\n",
    "        # Use IPython's Audio display widget (preferred for Jupyter)\n",
    "        try:\n",
    "            print(f\"Playing: {file_path}\")\n",
    "            display(Audio(file_path, autoplay=True))\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing audio with IPython: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2562336c-9c82-4c4e-89bd-de4f718de309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at ./recon_check/original.wav\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "dataset_path = \"./recon_check\"\n",
    "file_name = \"original.wav\"\n",
    "full_path = os.path.join(dataset_path, file_name)\n",
    "\n",
    "play_audio_jupyter(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f2eee-d766-4faf-aeba-0a91993c4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Path to your MP3\n",
    "mp3_path = \"./outputs/inference/03-01-05-01-01-01-08_original.mp3\"\n",
    "\n",
    "# Display an audio player\n",
    "Audio(mp3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf532a98-f199-4276-b430-a77724c1cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e240c7-fb47-4367-8d15-ab8dcabc0253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Happy audio files...\n",
      "Analyzing 2167 files in datasets/Happy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2167/2167 [00:00<00:00, 19527.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Happy audio files:\n",
      "Longest file: d15.wav (7.01 seconds)\n",
      "Shortest file: 1075_IEO_HAP_HI.wav (1.33 seconds)\n",
      "Mean duration: 2.67 seconds\n",
      "\n",
      "Analyzing Angry audio files...\n",
      "Analyzing 2167 files in datasets/Angry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2167/2167 [00:00<00:00, 11230.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Angry audio files:\n",
      "Longest file: su15.wav (5.86 seconds)\n",
      "Shortest file: OAF_whip_angry.wav (1.29 seconds)\n",
      "Mean duration: 2.77 seconds\n",
      "\n",
      "Overall Results:\n",
      "Longest file: Happy/d15.wav (7.01 seconds)\n",
      "Shortest file: Angry/OAF_whip_angry.wav (1.29 seconds)\n",
      "Mean duration across all files: 2.72 seconds\n",
      "Total files analyzed: 4334\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "def get_audio_duration(audio_path):\n",
    "    \"\"\"Get duration of an audio file in seconds\"\"\"\n",
    "    try:\n",
    "        duration = librosa.get_duration(path=audio_path)\n",
    "        return duration\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_audio_directory(directory_path):\n",
    "    \"\"\"Analyze all wav files in a directory and return duration statistics\"\"\"\n",
    "    # Get all wav files in the directory\n",
    "    wav_files = [f for f in os.listdir(directory_path) if f.endswith('.wav')]\n",
    "    \n",
    "    if not wav_files:\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    durations = []\n",
    "    longest_file = None\n",
    "    longest_duration = 0\n",
    "    shortest_file = None\n",
    "    shortest_duration = float('inf')\n",
    "    \n",
    "    print(f\"Analyzing {len(wav_files)} files in {directory_path}...\")\n",
    "    \n",
    "    # Process files with progress bar\n",
    "    for wav_file in tqdm.tqdm(wav_files):\n",
    "        audio_path = os.path.join(directory_path, wav_file)\n",
    "        \n",
    "        # Get audio duration\n",
    "        duration = get_audio_duration(audio_path)\n",
    "        \n",
    "        if duration is not None:\n",
    "            durations.append(duration)\n",
    "            \n",
    "            # Check if this is the longest file\n",
    "            if duration > longest_duration:\n",
    "                longest_duration = duration\n",
    "                longest_file = wav_file\n",
    "            \n",
    "            # Check if this is the shortest file\n",
    "            if duration < shortest_duration:\n",
    "                shortest_duration = duration\n",
    "                shortest_file = wav_file\n",
    "    \n",
    "    # Calculate mean duration\n",
    "    mean_duration = np.mean(durations) if durations else None\n",
    "    \n",
    "    return longest_file, longest_duration, shortest_file, shortest_duration, mean_duration\n",
    "\n",
    "def main():\n",
    "    # Define base directory\n",
    "    dataset_dir = \"datasets\"\n",
    "    \n",
    "    # Analyze Happy and Angry folders\n",
    "    emotions = [\"Happy\", \"Angry\"]\n",
    "    \n",
    "    all_durations = []\n",
    "    overall_longest_file = None\n",
    "    overall_longest_duration = 0\n",
    "    overall_shortest_file = None\n",
    "    overall_shortest_duration = float('inf')\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        input_dir = os.path.join(dataset_dir, emotion)\n",
    "        \n",
    "        # Check if the input directory exists\n",
    "        if os.path.exists(input_dir):\n",
    "            print(f\"\\nAnalyzing {emotion} audio files...\")\n",
    "            result = analyze_audio_directory(input_dir)\n",
    "            \n",
    "            if result:\n",
    "                longest_file, longest_duration, shortest_file, shortest_duration, mean_duration = result\n",
    "                \n",
    "                # Get all durations for this emotion and add to all_durations\n",
    "                emotion_wav_files = [f for f in os.listdir(input_dir) if f.endswith('.wav')]\n",
    "                for wav_file in emotion_wav_files:\n",
    "                    duration = get_audio_duration(os.path.join(input_dir, wav_file))\n",
    "                    if duration is not None:\n",
    "                        all_durations.append(duration)\n",
    "                \n",
    "                # Update overall longest\n",
    "                if longest_duration > overall_longest_duration:\n",
    "                    overall_longest_duration = longest_duration\n",
    "                    overall_longest_file = f\"{emotion}/{longest_file}\"\n",
    "                \n",
    "                # Update overall shortest\n",
    "                if shortest_duration < overall_shortest_duration:\n",
    "                    overall_shortest_duration = shortest_duration\n",
    "                    overall_shortest_file = f\"{emotion}/{shortest_file}\"\n",
    "                \n",
    "                # Print results for this emotion\n",
    "                print(f\"\\nResults for {emotion} audio files:\")\n",
    "                print(f\"Longest file: {longest_file} ({longest_duration:.2f} seconds)\")\n",
    "                print(f\"Shortest file: {shortest_file} ({shortest_duration:.2f} seconds)\")\n",
    "                print(f\"Mean duration: {mean_duration:.2f} seconds\")\n",
    "            else:\n",
    "                print(f\"No WAV files found in {input_dir}\")\n",
    "        else:\n",
    "            print(f\"Directory not found: {input_dir}\")\n",
    "    \n",
    "    # Print overall results\n",
    "    if all_durations:\n",
    "        overall_mean = np.mean(all_durations)\n",
    "        print(f\"\\nOverall Results:\")\n",
    "        print(f\"Longest file: {overall_longest_file} ({overall_longest_duration:.2f} seconds)\")\n",
    "        print(f\"Shortest file: {overall_shortest_file} ({overall_shortest_duration:.2f} seconds)\")\n",
    "        print(f\"Mean duration across all files: {overall_mean:.2f} seconds\")\n",
    "        print(f\"Total files analyzed: {len(all_durations)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9f191-1149-431e-8a7a-def5c7f9fb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d13e7-3fde-4b45-a638-35781df8f904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53135256-c166-4249-9fd3-acc317eece93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 47 characters from Text/Angry/su04.txt\n",
      "Saved speech as MP3: output.mp3\n",
      "Successfully converted to WAV: output.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gtts import gTTS\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "def text_to_audio(input_text_file, output_wav_file):\n",
    "    \"\"\"\n",
    "    Convert text from a file to speech and save as a WAV file using Google Text-to-Speech.\n",
    "    \n",
    "    Args:\n",
    "        input_text_file: Path to the input text file\n",
    "        output_wav_file: Path to save the output WAV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read text from the input file\n",
    "        with open(input_text_file, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        print(f\"Read {len(text)} characters from {input_text_file}\")\n",
    "        \n",
    "        # Create gTTS object\n",
    "        tts = gTTS(text=text, lang='en', slow=False)\n",
    "        \n",
    "        # Save as MP3 first (gTTS only outputs MP3)\n",
    "        mp3_file = str(output_wav_file).replace('.wav', '.mp3')\n",
    "        tts.save(mp3_file)\n",
    "        print(f\"Saved speech as MP3: {mp3_file}\")\n",
    "        \n",
    "        # Convert MP3 to WAV\n",
    "        # Check if output directory exists, create if not\n",
    "        output_dir = os.path.dirname(output_wav_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        from pydub import AudioSegment\n",
    "        sound = AudioSegment.from_mp3(mp3_file)\n",
    "        sound.export(output_wav_file, format=\"wav\")\n",
    "        print(f\"Successfully converted to WAV: {output_wav_file}\")\n",
    "        \n",
    "        # Remove temporary MP3 file\n",
    "        os.remove(mp3_file)\n",
    "    \n",
    "        print(\"Warning: pydub not installed. Could not convert MP3 to WAV.\")\n",
    "        print(f\"MP3 file saved at: {mp3_file}\")\n",
    "        print(\"Install pydub with 'pip install pydub' and ffmpeg for MP3 to WAV conversion.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in text to speech conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Convert text file to speech')\n",
    "    input_file='Text/Angry/su04.txt'\n",
    "    output_file='output.wav'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    text_to_audio(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff9d6e-3dde-4f75-8d08-10a21afc3510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab818cc0-3ec0-4aaf-a5cc-f2da3e29d47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Error: File not found at output.wav\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed (uncomment if necessary)\n",
    "# !pip install IPython pygame\n",
    "\n",
    "import pygame\n",
    "import os\n",
    "from IPython.display import display, Audio\n",
    "import time\n",
    "\n",
    "def play_audio_jupyter(file_path, use_pygame=False):\n",
    "    \"\"\"\n",
    "    Play an audio file in a Jupyter notebook\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the audio file\n",
    "        use_pygame (bool): Whether to use pygame for playback instead of IPython's Audio\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "    \n",
    "    if use_pygame:\n",
    "        # Initialize pygame mixer\n",
    "        pygame.mixer.init()\n",
    "        try:\n",
    "            # Load and play the sound\n",
    "            sound = pygame.mixer.Sound(file_path)\n",
    "            print(f\"Playing: {file_path}\")\n",
    "            print(f\"Duration: {sound.get_length():.2f} seconds\")\n",
    "            \n",
    "            # Play the sound\n",
    "            sound.play()\n",
    "            \n",
    "            # Keep the program running while the sound is playing\n",
    "            pygame.time.wait(int(sound.get_length() * 1000))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error playing audio with pygame: {e}\")\n",
    "        finally:\n",
    "            # Clean up resources\n",
    "            pygame.mixer.quit()\n",
    "    else:\n",
    "        # Use IPython's Audio display widget (preferred for Jupyter)\n",
    "        try:\n",
    "            print(f\"Playing: {file_path}\")\n",
    "            display(Audio(file_path, autoplay=True))\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing audio with IPython: {e}\")\n",
    "\n",
    "# Example usage\n",
    "dataset_path = \"\"\n",
    "file_name = \"output.wav\"\n",
    "full_path = os.path.join(dataset_path, file_name)\n",
    "\n",
    "play_audio_jupyter(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8d154e3-4fd3-42c2-b8f1-b9355962953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, click, jiwer\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "Successfully installed click-8.1.8 jiwer-3.1.0 rapidfuzz-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5708233-4362-48d7-8e42-a249eefa715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Happy_padded:\n",
      "  Min duration: 5.00 seconds\n",
      "  Max duration: 5.00 seconds\n",
      "  Mean duration: 5.00 seconds\n",
      "\n",
      "Stats for Angry_padded:\n",
      "  Min duration: 5.00 seconds\n",
      "  Max duration: 5.00 seconds\n",
      "  Mean duration: 5.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def get_audio_durations(folder_path):\n",
    "    durations = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    y, sr = librosa.load(file_path, sr=None)  # sr=None keeps the original sampling rate\n",
    "                    duration = librosa.get_duration(y=y, sr=sr)\n",
    "                    durations.append(duration)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "    return durations\n",
    "\n",
    "def print_stats(name, durations):\n",
    "    if durations:\n",
    "        print(f\"Stats for {name}:\")\n",
    "        print(f\"  Min duration: {np.min(durations):.2f} seconds\")\n",
    "        print(f\"  Max duration: {np.max(durations):.2f} seconds\")\n",
    "        print(f\"  Mean duration: {np.mean(durations):.2f} seconds\\n\")\n",
    "    else:\n",
    "        print(f\"No audio files found in {name}.\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_folder = \"datasets\"\n",
    "    emotions = [\"Happy_padded\", \"Angry_padded\"]\n",
    "\n",
    "    for emotion in emotions:\n",
    "        folder_path = os.path.join(base_folder, emotion)\n",
    "        durations = get_audio_durations(folder_path)\n",
    "        print_stats(emotion, durations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dfde818-1727-4783-8a06-36ffbea80dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mutagen\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mutagen\n",
      "Successfully installed mutagen-1.47.0\n"
     ]
    }
   ],
   "source": [
    "! pip install mutagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c447100-26ba-46a5-a297-e005f2389724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/jovyan/teaching_material/DL project \n",
      "\n",
      "Scanning: /home/jovyan/teaching_material/DL project/Audio_transformed/Happy_padded\n",
      "Happy_padded:\n",
      "  Files found:       1701\n",
      "  Shortest duration: 0:00:05.07  —  /home/jovyan/teaching_material/DL project/Audio_transformed/Happy_padded/03-01-03-01-01-02-03.mp3\n",
      "  Longest duration:  0:00:05.07  —  /home/jovyan/teaching_material/DL project/Audio_transformed/Happy_padded/03-01-03-01-01-02-03.mp3\n",
      "  Average duration:  0:00:05.07\n",
      "\n",
      "Scanning: /home/jovyan/teaching_material/DL project/Audio_transformed/Angry_padded\n",
      "Angry_padded:\n",
      "  Files found:       2108\n",
      "  Shortest duration: 0:00:05.07  —  /home/jovyan/teaching_material/DL project/Audio_transformed/Angry_padded/03-02-05-02-01-02-22.mp3\n",
      "  Longest duration:  0:00:05.07  —  /home/jovyan/teaching_material/DL project/Audio_transformed/Angry_padded/03-02-05-02-01-02-22.mp3\n",
      "  Average duration:  0:00:05.07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import statistics\n",
    "from mutagen.mp3 import MP3\n",
    "\n",
    "def folder_duration_stats(path):\n",
    "    \"\"\"\n",
    "    Walk through `path` and return:\n",
    "      count,\n",
    "      min_dur,\n",
    "      max_dur,\n",
    "      mean_dur,\n",
    "      shortest_file,\n",
    "      longest_file\n",
    "    where durations are in seconds.\n",
    "    \"\"\"\n",
    "    entries = []  # list of (full_path, duration)\n",
    "    for root, _, files in os.walk(path):\n",
    "        for fname in files:\n",
    "            if not fname.lower().endswith('.mp3'):\n",
    "                continue\n",
    "\n",
    "            full = os.path.abspath(os.path.join(root, fname))\n",
    "            if not os.path.exists(full):\n",
    "                print(f\"  Skipping missing file: {full}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                audio = MP3(full)\n",
    "                entries.append((full, audio.info.length))\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: could not read {full}: {e}\")\n",
    "\n",
    "    if not entries:\n",
    "        return 0, 0.0, 0.0, 0.0, None, None\n",
    "\n",
    "    # Extract just the durations\n",
    "    durations = [dur for _, dur in entries]\n",
    "    mean_dur = statistics.mean(durations)\n",
    "    min_entry = min(entries, key=lambda x: x[1])\n",
    "    max_entry = max(entries, key=lambda x: x[1])\n",
    "\n",
    "    return (\n",
    "        len(entries),\n",
    "        min_entry[1],\n",
    "        max_entry[1],\n",
    "        mean_dur,\n",
    "        min_entry[0],\n",
    "        max_entry[0],\n",
    "    )\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"\n",
    "    Convert seconds to H:MM:SS string.\n",
    "    \"\"\"\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{int(h)}:{int(m):02d}:{s:05.2f}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"CWD:\", os.getcwd(), \"\\n\")\n",
    "\n",
    "    base = \"Audio_transformed\"\n",
    "    for emotion in [\"Happy_padded\", \"Angry_padded\"]:\n",
    "        folder = os.path.join(base, emotion)\n",
    "        print(f\"Scanning: {os.path.abspath(folder)}\")\n",
    "        count, mn, mx, mean, shortest_file, longest_file = folder_duration_stats(folder)\n",
    "\n",
    "        print(f\"{emotion}:\")\n",
    "        print(f\"  Files found:       {count}\")\n",
    "        print(f\"  Shortest duration: {format_time(mn)}  —  {shortest_file}\")\n",
    "        print(f\"  Longest duration:  {format_time(mx)}  —  {longest_file}\")\n",
    "        print(f\"  Average duration:  {format_time(mean)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab24da-e0a5-466f-b47d-48f0d9775828",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "THIS CODE CONVERTS THE TEXT FILES TO AUDIO USING GTTS\n",
    "'''\n",
    "\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from gtts import gTTS\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import speedup\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "\n",
    "def get_file_hash(file_path):\n",
    "    \"\"\"\n",
    "    Get hash of file content to identify duplicate text files.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return hashlib.md5(content.encode()).hexdigest()\n",
    "\n",
    "def text_to_audio(input_text_file, output_mp3_file):\n",
    "    \"\"\"\n",
    "    Convert text from a file to speech and save as an MP3 file using Google Text-to-Speech.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read text from the input file\n",
    "        with open(input_text_file, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Create gTTS object (Indian English)\n",
    "        tts = gTTS(text=text, lang='en-in', slow=False, tld='co.in')\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        output_dir = os.path.dirname(output_mp3_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        # Save directly as MP3\n",
    "        tts.save(output_mp3_file)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error in text-to-speech conversion for {input_text_file}: {e}\")\n",
    "        return False\n",
    "\n",
    "def process_all_files(delay_seconds=3):\n",
    "    \"\"\"\n",
    "    Process all text files in the Text folder and its subfolders,\n",
    "    and save the corresponding MP3 files in the Audio folder.\n",
    "    Avoids duplicate API calls by reusing MP3 files for identical text content.\n",
    "    \n",
    "    Args:\n",
    "        delay_seconds: Number of seconds to wait between API calls\n",
    "    \"\"\"\n",
    "    # Create Audio folder if it doesn't exist\n",
    "    if not os.path.exists(\"Audio\"):\n",
    "        os.makedirs(\"Audio\")\n",
    "        print(\"Created Audio folder\")\n",
    "    \n",
    "    # Create Audio/Happy and Audio/Angry folders if they don't exist\n",
    "    for emotion in [\"Happy\", \"Angry\"]:\n",
    "        emotion_folder = os.path.join(\"Audio\", emotion)\n",
    "        if not os.path.exists(emotion_folder):\n",
    "            os.makedirs(emotion_folder)\n",
    "            print(f\"Created {emotion_folder} folder\")\n",
    "    \n",
    "    # Process all text files\n",
    "    text_base_path = \"Text\"\n",
    "    \n",
    "    # Dictionary to store already processed content hashes and their corresponding MP3 files\n",
    "    content_hash_to_mp3 = {}\n",
    "    \n",
    "    # Process each emotion folder\n",
    "    for emotion in [\"Happy\", \"Angry\"]:\n",
    "        emotion_path = os.path.join(text_base_path, emotion)\n",
    "        \n",
    "        # Skip if folder doesn't exist\n",
    "        if not os.path.exists(emotion_path):\n",
    "            print(f\"Warning: {emotion_path} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        # Get all text files in the emotion folder\n",
    "        text_files = [f for f in os.listdir(emotion_path) if f.endswith(\".txt\")]\n",
    "        \n",
    "        if not text_files:\n",
    "            print(f\"No text files found in {emotion_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing {emotion} files:\")\n",
    "        \n",
    "        # Process files with progress bar\n",
    "        for text_file in tqdm(text_files, desc=f\"{emotion}\", unit=\"file\"):\n",
    "            input_path = os.path.join(emotion_path, text_file)\n",
    "            output_path = os.path.join(\"Audio\", emotion, text_file.replace(\".txt\", \".mp3\"))\n",
    "            \n",
    "            # Get hash of file content\n",
    "            file_hash = get_file_hash(input_path)\n",
    "            \n",
    "            # Check if we've already processed this content\n",
    "            if file_hash in content_hash_to_mp3:\n",
    "                # Reuse existing MP3 file instead of making a new API call\n",
    "                source_mp3 = content_hash_to_mp3[file_hash]\n",
    "                shutil.copy2(source_mp3, output_path)\n",
    "                tqdm.write(f\"Copied existing MP3 for duplicate content: {text_file}\")\n",
    "            else:\n",
    "                # Process new unique content\n",
    "                success = text_to_audio(input_path, output_path)\n",
    "                \n",
    "                if success:\n",
    "                    # Store the hash and MP3 path for future reuse\n",
    "                    content_hash_to_mp3[file_hash] = output_path\n",
    "                    \n",
    "                    # Add delay only for new API calls\n",
    "                    if text_file != text_files[-1]:  # No need to delay after the last file\n",
    "                        time.sleep(delay_seconds)\n",
    "\n",
    "    # Report stats\n",
    "    unique_files = len(content_hash_to_mp3)\n",
    "    total_files = sum(len([f for f in os.listdir(os.path.join(text_base_path, e)) if f.endswith(\".txt\")]) \n",
    "                    for e in [\"Happy\", \"Angry\"] if os.path.exists(os.path.join(text_base_path, e)))\n",
    "    \n",
    "    print(f\"\\nProcessing complete! {unique_files} unique text contents found out of {total_files} total files.\")\n",
    "    print(f\"Saved {total_files - unique_files} API calls by reusing existing MP3 files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_files(delay_seconds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca193472-9d99-4d62-a589-0a688056b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Modifies the pitch of the audio files and saved the modified files to Audio_transformed\n",
    "'''\n",
    "\n",
    "def convert_to_male_voice(input_audio_file, output_audio_file):\n",
    "    try:\n",
    "        # Determine file format from extension\n",
    "        input_format = os.path.splitext(input_audio_file)[1][1:]\n",
    "        \n",
    "        # Load the audio file\n",
    "        sound = AudioSegment.from_file(input_audio_file, format=input_format)\n",
    "        \n",
    "        # Lower the pitch by modifying the sound\n",
    "        slowdown_factor = 0.85  # 15% slower\n",
    "        male_voice_sound = sound._spawn(sound.raw_data, overrides={\n",
    "            \"frame_rate\": int(sound.frame_rate * slowdown_factor)\n",
    "        })\n",
    "        \n",
    "        # Speed up tempo without affecting pitch\n",
    "        male_voice_sound = speedup(male_voice_sound, 1.25, 150)\n",
    "        \n",
    "        # Apply low-pass filter for a more masculine sound\n",
    "        male_voice_sound = male_voice_sound.low_pass_filter(300)\n",
    "        \n",
    "        # Export the modified audio\n",
    "        output_format = os.path.splitext(output_audio_file)[1][1:]\n",
    "        male_voice_sound.export(output_audio_file, format=output_format)\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_audio_file}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302b4ff-98c7-43f7-9576-2ded9dcb263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluation of the TTS model by checking non english files\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from langdetect import detect, LangDetectException\n",
    "from tqdm import tqdm\n",
    "\n",
    "def is_english(text):\n",
    "    \"\"\"\n",
    "    Detect if text is in English.\n",
    "    Returns True if English, False otherwise.\n",
    "    \"\"\"\n",
    "    if not text or text.strip() == \"\":\n",
    "        return False  # Empty text can't be detected\n",
    "    \n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return lang == 'en'\n",
    "    except LangDetectException:\n",
    "        return False  # If detection fails, consider it non-English\n",
    "\n",
    "def check_non_english_files(directory_path):\n",
    "    \"\"\"\n",
    "    Check all text files in a directory to identify non-English content.\n",
    "    Returns a list of dictionaries with file paths and detected languages.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get all txt files in the directory\n",
    "    txt_files = [f for f in os.listdir(directory_path) if f.endswith('.txt')]\n",
    "    \n",
    "    print(f\"Checking {len(txt_files)} files in {directory_path}...\")\n",
    "    \n",
    "    # Process files with progress bar\n",
    "    for txt_file in tqdm(txt_files):\n",
    "        file_path = os.path.join(directory_path, txt_file)\n",
    "        \n",
    "        # Read text file\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Check if content is English\n",
    "            is_eng = is_english(content)\n",
    "            \n",
    "            if not is_eng:\n",
    "                try:\n",
    "                    detected_lang = detect(content) if content.strip() else \"empty\"\n",
    "                except LangDetectException:\n",
    "                    detected_lang = \"unknown\"\n",
    "                \n",
    "                results.append({\n",
    "                    'file': txt_file,\n",
    "                    'path': file_path,\n",
    "                    'detected_language': detected_lang,\n",
    "                    'content_sample': content[:100] + '...' if len(content) > 100 else content\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'file': txt_file,\n",
    "                'path': file_path,\n",
    "                'error': str(e),\n",
    "                'detected_language': 'error'\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Define base directory\n",
    "    text_dir = \"Text_evaluation_tts\"\n",
    "    \n",
    "    # Check if the base directory exists\n",
    "    if not os.path.exists(text_dir):\n",
    "        print(f\"Directory not found: {text_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Process Happy and Angry folders\n",
    "    emotions = [\"Happy\", \"Angry\"]\n",
    "    all_results = []\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        input_dir = os.path.join(text_dir, emotion)\n",
    "        \n",
    "        # Check if the emotion directory exists\n",
    "        if os.path.exists(input_dir):\n",
    "            print(f\"\\nChecking {emotion} text files...\")\n",
    "            results = check_non_english_files(input_dir)\n",
    "            \n",
    "            # Add emotion information to results\n",
    "            for item in results:\n",
    "                item['emotion'] = emotion\n",
    "            \n",
    "            all_results.extend(results)\n",
    "        else:\n",
    "            print(f\"Directory not found: {input_dir}\")\n",
    "    \n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Display summary\n",
    "        print(\"\\n===== SUMMARY =====\")\n",
    "        print(f\"Total non-English files found: {len(df)}\")\n",
    "        \n",
    "        if not df.empty:\n",
    "            # Count by language\n",
    "            lang_counts = df['detected_language'].value_counts()\n",
    "            print(\"\\nDetected languages:\")\n",
    "            print(lang_counts)\n",
    "            \n",
    "            # Count by emotion\n",
    "            emotion_counts = df['emotion'].value_counts()\n",
    "            print(\"\\nNon-English files by emotion:\")\n",
    "            print(emotion_counts)\n",
    "            \n",
    "            # Save results to CSV\n",
    "            output_file = \"non_english_files.csv\"\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"\\nDetailed results saved to {output_file}\")\n",
    "        \n",
    "        # Return percentage of non-English files\n",
    "        total_files = sum(len([f for f in os.listdir(os.path.join(text_dir, e)) if f.endswith('.txt')]) \n",
    "                       for e in emotions if os.path.exists(os.path.join(text_dir, e)))\n",
    "        \n",
    "        if total_files > 0:\n",
    "            percentage = (len(df) / total_files) * 100\n",
    "            print(f\"\\nPercentage of non-English files: {percentage:.2f}% ({len(df)} out of {total_files})\")\n",
    "    else:\n",
    "        print(\"\\nAll files appear to be in English.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"\\nLanguage detection completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea92939-1095-4568-9dac-d86bd6932c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Whisper to convert audio to text\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import librosa\n",
    "import tqdm\n",
    "# Set up device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "# Load the Whisper model \n",
    "model_id = \"openai/whisper-large\"\n",
    "print(f\"Loading {model_id}...\")\n",
    "processor = WhisperProcessor.from_pretrained(model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_id).to(device)\n",
    "print(\"Model loaded successfully\")\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Transcribe audio file to text using Whisper model\"\"\"\n",
    "    try:\n",
    "        # Load and resample audio\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "        \n",
    "        # Process audio\n",
    "        input_features = processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_features.to(device)\n",
    "        \n",
    "        # Generate transcription\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(input_features=input_features)\n",
    "        \n",
    "        # Decode the output\n",
    "        transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return transcription\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return \"\"\n",
    "def process_directory(directory_path, output_text_dir):\n",
    "    \"\"\"Process all wav files in a directory and save transcriptions\"\"\"\n",
    "    os.makedirs(output_text_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all wav files in the directory\n",
    "    wav_files = [f for f in os.listdir(directory_path) if f.endswith('.mp3')]\n",
    "    \n",
    "    print(f\"Processing {len(wav_files)} files in {directory_path}...\")\n",
    "    \n",
    "    # Process files with progress bar\n",
    "    for wav_file in tqdm.tqdm(wav_files):\n",
    "        audio_path = os.path.join(directory_path, wav_file)\n",
    "        text_filename = os.path.splitext(wav_file)[0] + '.txt'\n",
    "        text_path = os.path.join(output_text_dir, text_filename)\n",
    "        \n",
    "        # Transcribe audio\n",
    "        transcription = transcribe_audio(audio_path)\n",
    "        \n",
    "        # Save transcription to text file\n",
    "        with open(text_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(transcription)\n",
    "def main():\n",
    "    # Define base directories\n",
    "    dataset_dir = \"Audio\"\n",
    "    text_output_dir = \"Text_evaluation_tts\"\n",
    "    \n",
    "    # Create the main text output directory\n",
    "    os.makedirs(text_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process Happy and Angry folders\n",
    "    emotions = [\"Happy\", \"Angry\"]\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        input_dir = os.path.join(dataset_dir, emotion)\n",
    "        output_dir = os.path.join(text_output_dir, emotion)\n",
    "        \n",
    "        # Check if the input directory exists\n",
    "        if os.path.exists(input_dir):\n",
    "            print(f\"\\nProcessing {emotion} audio files...\")\n",
    "            process_directory(input_dir, output_dir)\n",
    "        else:\n",
    "            print(f\"Directory not found: {input_dir}\")\n",
    "if **name** == \"__main__\":\n",
    "    main()\n",
    "    print(\"\\nTranscription process completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe2327-28a0-4097-9f79-53524b18836e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643994cc-6e1b-41f6-8733-04499c3b7f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235352d7-3fc6-407a-be51-d93d267460a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac78495-5ba6-45bc-8f3b-ff508879d7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
